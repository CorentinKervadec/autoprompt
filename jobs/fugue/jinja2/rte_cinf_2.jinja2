{% for template, initial_trigger in [
    ('{sentence2} [T] [T] [P] [T] {sentence1}', ['?', '|', ',']),
    ('[T] {sentence2} [T] [T] [T] [P] [T] [T] {sentence1} [T]', ['"', '"', '?', '|', ',', '"', '"']),
    ('{sentence2} [T] </s> [P] [T] {sentence1}', ['?', ',']),
    ('[T] {sentence2} [T] [T] </s> [P] [T] [T] {sentence1} [T]', ['"', '"', '?', ',', '"', '"']),
] -%}
{% set template_idx = loop.index %}
{% for pet in [True, False] -%}
{% for label_map in [
    '{"entailment": "yes", "not_entailment": "no"}',
] -%}
{% set label_idx = loop.index %}
{% for accumulation_steps in [1, 2, 4] -%}
---
out: rte-cinf_model_roberta-large_template_{{template_idx}}_initial-trigger_{{pet}}_label-map_{{label_idx}}_lr_1e-3_accumulation-steps_{{accumulation_steps}}_finetune-mode_trigger
script: autoprompt/continuous_trigger_mlm.py
args:
    - '--model-name'
    - 'roberta-large'
    - '--train'
    - 'data/LittleGLUE/RTE/train.jsonl'
    - '--dev'
    - 'data/LittleGLUE/RTE/dev.jsonl'
    - '--test'
    - 'data/LittleGLUE/RTE/dev_all.jsonl'
    - '--ckpt-dir'
    - 'ckpt/rte-cinf_model_roberta-large_template_{{template_idx}}_initial-trigger_{{pet}}_label-map_{{label_idx}}_lr_1e-3_accumulation-steps_{{accumulation_steps}}_finetune-mode_trigger'
    - '--evaluation-strategy'
    - 'classification'
    - '--finetune-mode'
    - 'trigger'
    - '--template'
    - '{{template}}'
    - '--label-map'
    - '{{label_map}}'
    - '--epochs'
    - '30'
    - '--bsz'
    - '2'
    - '--clip'
    - '1.0'
    - '--accumulation-steps'
    - '{{accumulation_steps}}'
    - '--lr'
    - '1e-3'
{% if pet %}
    - '--initial-trigger' 
{% for token in initial_trigger %}
    - '{{token}}'
{% endfor %}
{% endif %}
    - '--quiet'
    - '--tmp'
    - '-f'
...
{% endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
{# ================================ #}
{% for template, initial_trigger in [
    ('{sentence2} [T] [T] [P] [T] {sentence1}', ['?', '|', ',']),
    ('[T] {sentence2} [T] [T] [T] [P] [T] [T] {sentence1} [T]', ['"', '"', '?', '|', ',', '"', '"']),
    ('{sentence2} [T] [SEP] [P] [T] {sentence1}', ['?', ',']),
    ('[T] {sentence2} [T] [T] [SEP] [P] [T] [T] {sentence1} [T]', ['"', '"', '?', ',', '"', '"']),
] -%}
{% set template_idx = loop.index %}
{% for pet in [True, False] -%}
{% for label_map in [
    '{"entailment": "yes", "not_entailment": "no"}',
] -%}
{% set label_idx = loop.index %}
{% for accumulation_steps in [1, 2, 4] -%}
---
out: rte-cinf_model_albert-xxlarge-v2_template_{{template_idx}}_initial-trigger_{{pet}}_label-map_{{label_idx}}_lr_1e-3_accumulation-steps_{{accumulation_steps}}_finetune-mode_trigger
script: autoprompt/continuous_trigger_mlm.py
args:
    - '--model-name'
    - 'albert-xxlarge-v2'
    - '--train'
    - 'data/LittleGLUE/RTE/train.jsonl'
    - '--dev'
    - 'data/LittleGLUE/RTE/dev.jsonl'
    - '--test'
    - 'data/LittleGLUE/RTE/dev_all.jsonl'
    - '--ckpt-dir'
    - 'ckpt/rte-cinf_model_albert-xxlarge-v2_template_{{template_idx}}_initial-trigger_{{pet}}_label-map_{{label_idx}}_lr_1e-3_accumulation-steps_{{accumulation_steps}}_finetune-mode_trigger'
    - '--evaluation-strategy'
    - 'classification'
    - '--finetune-mode'
    - 'trigger'
    - '--template'
    - '{{template}}'
    - '--label-map'
    - '{{label_map}}'
    - '--epochs'
    - '30'
    - '--bsz'
    - '2'
    - '--clip'
    - '1.0'
    - '--accumulation-steps'
    - '{{accumulation_steps}}'
    - '--lr'
    - '1e-3'
{% if pet %}
    - '--initial-trigger' 
{% for token in initial_trigger %}
    - '{{token}}'
{% endfor %}
{% endif %}
    - '--quiet'
    - '--tmp'
    - '-f'
...
{% endfor %}
{%- endfor %}
{%- endfor %}
{%- endfor %}
